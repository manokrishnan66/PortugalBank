---
title: "HarvardX: PH125.9x Data Science  \n   Portugal Banking term loan prediction"
author: "Mano Krishnan"
date: "02/04/2020"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
---
\pagebreak

# Introduction

We chose Bank Marketing Data set for the final project on Data science. This is Portuguese Banking institutional data. It has many attributes including a client's subscription to term deposit or not. The aim is to build models that can predict whether client will subscribe to term deposit or not.


## Dataset and Data Loading

This dataset is downloaded from UCI Machi Learning Repository. This is related to direct marketing campaigns of the Portuguese Banking institution. This dataset is available at http://archive.ics.uci.edu/ml/datasets/Bank+Marketing. There were 4 datasets in it from which bank-full.csv is used that has all examples (45211) and 17 inputs ordered by date. There are 16 input variables and 1 output variable (desired target).

This had different categories of client data like job, age, marital, education, default, housing, loan, contact, month, balance, day_of_week, duration, campaign, pdays, previous, poutcome and one output variable y that denotes if client subscribed to term deposit or not. These data denote telemarketing data, customer data and some other data. Here, many attributes are numerical and some are categorical. We loaded the dataset in the R studio and checked for any missing values using is.na fucntion and found not missing data. Hence, we have clean data.

### Libraries

The following libraries were used in this report:
```{r libs, warning=FALSE, error=FALSE, message=FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org")
if(!require(rpart.plot)) install.packages("rpart.plot", repos = "http://cran.us.r-project.org")
if(!require(rattle)) install.packages("rattle", repos = "http://cran.us.r-project.org")
if(!require(RColorBrewer)) install.packages("RColorBrewer", repos = "http://cran.us.r-project.org")
if(!require(descr)) install.packages("descr", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
```

### Dataset loading

```{r data_load, warning=FALSE, error=FALSE, message=FALSE}
Portdata <- read_delim("bank-full.csv", 
                         ";", escape_double = FALSE, trim_ws = TRUE)
## Duplicate row check
sum(duplicated(Portdata))

## Missing data check
sum(!complete.cases(Portdata))

all.empty = rowSums(is.na(Portdata))==ncol(Portdata)
sum(all.empty)

Portdata.clean = Portdata[!all.empty,]

Portdata.clean = Portdata.clean %>% distinct

nrow(Portdata.clean)

Portdata.clean$missing = !complete.cases(Portdata.clean)

sum(is.na(Portdata))

```
### Attribute Information: 
1. age – Client Age- (numeric) 
2. job – Type of Job - (categorical) ('admin.','blue-collar','entrepreneur','housemaid','management',
'retired','selfemployed','services',
'student','technician','unemployed','unknown') 
3. marital - Client’s marital status - (categorical) (divorced, married, single, unknown, note: divorced means divorced or widowed) 
4. education - Client’s education - (categorical) (basic.4y, basic.6y, basic.9y, high.school, illiterate, professional.course, university.degree, unknown) 
5. default - has credit in default? - (categorical) (no, yes, unknown) 
6. housing - Has housing loan? - (categorical) (no, yes, unknown) 
7. loan - has personal loan? - (categorical) (no, yes, unknown’) 
8. contact – last contact month of year - (categorical) (cellular, telephone) 
9. month - Month of last contact with client - (categorical) (January - December) 
10. day - last contact day of the month - (categorical) (1-31) 
11. duration - last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no').  
12. campaign: number of contacts performed during this campaign and for this client (numeric)  
13. pdays - number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means clients were not previously contacted)  
14. previous - Number of client contacts performed before this campaign - (numeric) 
15. poutcome - outcome of the previous marketing campaign - (categorical) (failure, nonexistent, success) 
16. balance - balance of the saving account - (numeric)

Output variable (desired target) –  
17. Term Deposit - has the client subscribed a term deposit?  - (binary: ‘yes’,‘no’) 

### Aim & Objectives

The provided dataset will be divided into training set and validation set. We are training the first set with the machine learning algorithms and to predict subscription of term deposit by the client.

Data visualization and data exploration is used to find the interesting trends and the factors affecting the term deposit subscription by the client. We are creating many models based on their resulting accuracy and other attributes and finalizing the optimal model to client's subscription.  

# Methodology & Analysis
## Data Pre-processing

For better analysis, we have mutated many attributes based on the logical segregation. The below mentioned attributes were mutated.

1. Age_group - Grouped age data into 4 categories. 

If age is less than 21, we consider it as 'Below 20' group. 
If age is between 21 and 40, we consider it as 'Between 21 and 40' group. 
If age is between 41 and 60, we consider it as 'Between 41 and 60' group. 
If age is greater than 60, we consider it as 'Above 61' group.

2. Cust_group - Grouped balance data into 4 categories

If balance is less than 0, we consider it as 'Below zero' group. 
If balance is between 1 and mean of the total balance amount , we consider it as 'below average' group. 
If balance is between mean of the total balance amount and 50000 , we consider it as 'Above average' group.
If balance is greater than 50000, we consider it as 'HNI' group. 

3. day_group - Grouped day data into 4 categories

If day is between 1 and 10 , we consider it as 'Early Month' group. If day is between 11 and 20 , we consider it as 'Mid month' group.
If day is between 21 and 31, we consider it as 'Month end' group. 

4. Duration_group - Grouped duration data into 4 categories

If duration is between 1 and mean of the duration , we consider it as 'Less Duration' group. 
If duration is between mean of the duration and 750 , we consider it as 'Good Duration' group.
If duration is between 750 and 1500, we consider it as 'High Duration' group. 
If duration is above 1500, we consider it as 'Very High Duration' group. 

5. Campaign_group - Grouped campaign data into 4 categories

If campaign is between 1 and mean of the campaign , we consider it as 'Average Campaign' group. 
If campaign is between mean of the campaign and 10, we consider it as 'Average Campaign' group.
If campaign is between 10 and 20, we consider it as 'Ample Campaign' group. 
If campaign is above 20, we consider it as 'Heavy Campaign' group.

6. pdays_group - Grouped pdays data into 4 categories

If pdays is between -1 and mean of the pdays , we consider it as 'Less gap Pdays' group. 
If pdays is between mean of the pdays and 100, we consider it as 'Medium gap Pdays' group.
If pdays is greater 100, we consider it as 'Large gap Pdays' group. 
7. previous_group - Grouped previous data into 4 categories

If previous is 0 , we consider it as 'Zero' group. 
If previous is 1, we consider it as 'One' group.
If previous is more than 1, we consider it as 'More than once' group.

8. y-output is "no", then 0 and if it is "yes", then 1.

``````{r Pre-processing, warning=FALSE, error=FALSE, message=FALSE}
Portdata <- as.data.frame(Portdata)

Portdata <- Portdata %>% mutate(Age_group = ifelse(age < 21,
            "Below 20", ifelse(between(age, 21,40), 
            "Between 21 and 40", ifelse(between(age,41,60),        
            "Between 41 and 60", "Above 61"))))

Portdata <- Portdata %>% mutate(Cust_group = ifelse(balance <0, 
            "below zero", ifelse(between(balance,1,mean(balance)),
            "below average",     
            ifelse(between(balance,mean(balance),50000), 
            "Above average", "HNI" ))))

Portdata <- Portdata %>% mutate(day_group =  
            ifelse(between(day,1,10),"Early Month", 
            ifelse(between(day,11,20),"Mid Month", "Month End")))

Portdata <- Portdata %>% mutate(Duration_group = 
            ifelse(between(duration,0,mean(duration)),"Less 
            Duration", ifelse(between(duration,mean(duration),750),
            "Good Duration", ifelse(between(duration, 750, 1500),
            "High Duration", "Very High Duration" ))))


Portdata <- Portdata %>% mutate(Campaign_group = 
            ifelse(between(campaign,1,mean(campaign)),
            "Lean Campaign", ifelse(between(campaign,
            mean(campaign),10),"Average Campaign", 
            ifelse(between(campaign, 10, 20),
            "Ample Campaign", "Heavy Campaign" ))))

Portdata <- Portdata %>% mutate(pdays_group = 
            ifelse(between(pdays,-1,mean(pdays)), "Less gap 
            Pdays", ifelse( between(pdays,mean(pdays), 100),
            "Medium gap Pdays", "Large gap Pdays")))

Portdata <- Portdata %>% mutate(previous_group = 
            ifelse(previous == 0, "Zero", ifelse(previous==1, 
            "One", "More than once")))

Portdata <- Portdata %>% mutate(y_output = ifelse(y == "no", 0, 1))

Portdata <- Portdata %>% mutate(y_output = as.factor(y_output))

Portdata <- Portdata %>% select(-age,-balance,-day,-duration,-campaign,-pdays,-previous,-y)

Portdata <- Portdata %>% mutate(Age_group = as.factor(Age_group),
                                Cust_group = as.factor(Cust_group),
                                day_group = as.factor(day_group),
                                Duration_group = as.factor(Duration_group),
                                Campaign_group = as.factor(Campaign_group),
                                previous_group = as.factor(previous_group),
                                Duration_group = as.factor(Duration_group),
                                y_output = as.factor(y_output) )


Portdata=Portdata %>% mutate_if(is.character, as.factor)

```

## Data Visualization and Data Exploration

### General Data Information

```{r General_data_info}
# The few rows of the Portdata are presented below:
head(Portdata) 

# Summary Statistics of Portdata
summary(Portdata)
```

## Data exploration

Each attribute of the dataset has been explored properly by comparing the count of the y_output.

```{r data_exploration}
### Exploration of Age attribute
  
Age_count <- data.frame(Portdata %>% group_by(Age_group, y_output) %>% summarise(Count = n()))

Age_count <- Age_count %>% spread(y_output,Count) %>% 
rename(No = `0`, Yes = `1` ) %>% 
mutate(Percent_of_yes = Yes /(Yes + No)) %>% 
arrange(desc(Percent_of_yes))  

Age_count %>% knitr::kable()

Portdata %>% ggplot(aes(Age_group, color = y_output)) + 
  geom_bar() + 
  labs(title = "Term Deposits Yes/No by Age Count", x="age", 
  y="Count of Output") +
  facet_wrap(y_output ~ .) +
  coord_flip()

theme_set(theme_bw())  # pre-set the bw theme.
g <- Portdata %>% ggplot( aes(y_output, Age_group)) + 
labs(subtitle="Term deposit output vs Age Group",
Y="Age Group", x="Count of Output")

g + geom_jitter(aes(col=Age_group)) + 
  geom_smooth(aes(col=Age_group), method="lm", se=F)

### Exploration of Job atrribute

job_count <- data.frame(Portdata %>% group_by(job,y_output) %>% summarise(Count = n()))

job_count <- job_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

job_count %>% knitr::kable()

### Exploration of Marital status

Marital_count <- data.frame(Portdata %>% group_by(marital,y_output) %>% summarise(Count = n()))

Marital_count <- Marital_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Marital_count %>% knitr::kable()

Portdata %>% ggplot(aes(marital, fill = y_output)) + 
  geom_bar() + 
  labs(title = "Term Deposits Yes/No by Marital status", x="Marital status", y="Count of Output") +
  facet_wrap(y_output ~ .) +
  coord_flip()

### Exploration of Education attribute

Education_count <- data.frame(Portdata %>% group_by(education,y_output) %>% summarise(Count = n()))

Education_count <- Education_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Education_count %>% knitr::kable()

### Exploration of Default attribute

Default_count <- data.frame(Portdata %>% group_by(default,y_output) %>% summarise(Count = n()))

Default_count <- Default_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Default_count %>% knitr::kable()

### Exploration of Housing attribute

Housing_count <- data.frame(Portdata %>% group_by(housing,y_output) %>% summarise(Count = n()))

Housing_count <- Housing_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Housing_count %>% knitr::kable()

### Exploration of Loan attribute

Loan_count <- data.frame(Portdata %>% group_by(loan,y_output) %>% summarise(Count = n()))

Loan_count <- Loan_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Loan_count %>% knitr::kable()

Portdata %>% ggplot(aes(loan, fill = y_output)) + 
  geom_bar() + 
  labs(title = "Term Deposits Yes/No by Loan count", x="Loan count", y="Count of Output") +
  facet_wrap(y_output ~ .) +
  coord_flip()

### Exploration of Contact attribute

Contact_count <- data.frame(Portdata %>% group_by(contact,y_output) %>% summarise(Count = n()))

Contact_count <- Contact_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Contact_count %>% knitr::kable()

Portdata %>% ggplot(aes(contact, y_output, color = contact)) + 
  geom_jitter()

### Exploration of Month attribute

Month_count <- data.frame(Portdata %>% group_by(month,y_output) %>% summarise(Count = n()))

Month_count <- Month_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Month_count %>% knitr::kable()


Portdata %>% ggplot(aes(month, fill = y_output)) + 
  geom_bar() + 
  labs(title = "Term Deposits Yes/No by contacted month", x="Contacted month", y="Count of Output") +
  facet_wrap(y_output ~ .) +
  coord_flip()

### Exploration of Poutcome attribute

Pout_count <- data.frame(Portdata %>% group_by(poutcome,y_output) %>% summarise(Count = n()))

Pout_count <- Pout_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Pout_count %>% knitr::kable()


Portdata %>% ggplot(aes(poutcome, fill = y_output)) + 
  geom_bar() + 
  labs(title = "Term Deposits Yes/No by previous campaign outcome",
  x="Previous campaign outcome", y="Count of Output") +
  facet_wrap(y_output ~ .) +
  coord_flip()

### Exploration of Customer attribute

Cust_count <- data.frame(Portdata %>% group_by(Cust_group,y_output) %>% summarise(Count = n()))

Cust_count <- Cust_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Cust_count %>% knitr::kable()

Portdata %>% ggplot(aes(Cust_group, y_output, color = Cust_group)) + 
  geom_jitter()

### Exploration of day_group attributes

Day_count <- data.frame(Portdata %>% group_by(day_group,y_output) %>% summarise(Count = n()))

Day_count <- Day_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Day_count %>% knitr::kable()

Portdata %>% ggplot(aes(day_group, fill = y_output)) + 
  geom_bar() + 
  labs(title = "Term Deposits Yes/No by campaign period", 
  x="Previous campaign period", y="Count of Output") +
  facet_wrap(y_output ~ .) +
  coord_flip()

### Exploration of Duration attributes

Duration_count <- data.frame(Portdata %>% group_by(Duration_group,y_output) %>% summarise(Count = n()))

Duration_count <- Duration_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Duration_count %>% knitr::kable()

Portdata %>% ggplot(aes(Duration_group, y_output, color = Duration_group)) + 
  geom_jitter()

### Exploration of Campaign_group attributes

Campaign_count <- data.frame(Portdata %>% group_by(Campaign_group,y_output) %>% summarise(Count = n()))

Campaign_count <- Campaign_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

Campaign_count %>% knitr::kable()

### Exploration of pdays_group attributes

pdays_count <- data.frame(Portdata %>% group_by(pdays_group,y_output) %>% summarise(Count = n()))

pdays_count <- pdays_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

pdays_count %>% knitr::kable()


Portdata %>% ggplot(aes(pdays_group, fill = y_output)) + 
  geom_bar() + 
  labs(title = "Term Deposits Yes/No by previous contact gap", 
  x="Previous contact gap", y="Count of Output") +
  facet_wrap(y_output ~ .) +
  coord_flip()

### Exploration of previous_group attributes

previous_count <- data.frame(Portdata %>% group_by(previous_group,y_output) %>% summarise(Count = n()))

previous_count <- previous_count %>% spread(y_output,Count) %>% rename(No = `0`, Yes = `1` ) %>% 
  mutate(Percent_of_yes = Yes /(Yes + No)) %>% arrange(desc(Percent_of_yes))  

previous_count %>% knitr::kable()


Portdata %>% ggplot(aes(previous_group, y_output, color = previous_group)) + 
  geom_jitter()

```

Based on the above exploration, we can understand that some of the attributes contribute more to the clients subscription decision. We have mentioned below the list of attributes in the order of high impact.

1. Duration_group -  last contact duration
2. Month - Month of last contact with client 
3. Poutcome - outcome of the previous marketing campaign 
4. Age_group - Client Age
5. pdays_group - number of days that passed by after the client was last contacted from a previous campaign 

### Splitting of dataset

We had partitioned the banking dataset into 2 sets[main dataset and validation dataset in the 90:10 ratio]. The main datset is further split into train and test dataset[in the 80:20 ratio]. We were training the dataset with the train set and testing with the test dataset.Then, based on the test results, we had finalised the model. Finally, we implemented the model in the validation dataset for the conclusion. 



```{r Split_data}

# Validation set will be 10% of bank marketing data
set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
Valid_index <- createDataPartition(y = Portdata$y, times = 1, p = 0.1, list = FALSE)
Portdata_main <- Portdata[-Valid_index,]
Portdata_validation <- Portdata[Valid_index,]

# Splitting Portdata_main into 2 sets for initial testing
set.seed(2, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = Portdata_main$y, times = 1, p = 0.2, list = FALSE)
Portdata_main_train <- Portdata_main[-test_index,]
Portdata_main_test <- Portdata_main[test_index,]
```


## Data Analysis and modelling

### GLM:

Logistic regression is useful when you are predicting a binary outcome from a set of continuous predictor variables. It is frequently preferred over discriminant function analysis because of its less restrictive assumptions.

```{r GLM_data}

glm_fit <- Portdata_main_train %>% 
    glm(y_output ~ ., data=., family = binomial(link='logit'))

p_hat_logit <- predict(glm_fit, newdata = Portdata_main_test, type = "response") 
y_hat_logit <- ifelse(p_hat_logit > 0.25,1, 0) %>% factor

### Cross table of GLM - All attributes
CrossTable(Portdata_main_test$y_output, y_hat_logit,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

### Confusion matrix of GLM - All attributes
conf_glm <- confusionMatrix(y_hat_logit, 
Portdata_main_test$y_output, mode = "prec_recall", positive = '1')

conf_glm

accuracy_glm = conf_glm$overall[["Accuracy"]]
Sensitivity_glm = conf_glm$byClass[["Sensitivity"]]
Specificity_glm = conf_glm$byClass[["Specificity"]]
Precision_glm = conf_glm$byClass[["Precision"]]
F1_glm = conf_glm$byClass[["F1"]]

## creation of confusion table for GLM - All attributes
Confusion_table <- data_frame(method = "GLM - All attributes", 
      Accuracy =accuracy_glm,SensitivityorRecall = Sensitivity_glm,
      Specificity=Specificity_glm,Precision = Precision_glm, 
      F1= F1_glm  )

Confusion_table <- as.data.frame(Confusion_table)

Confusion_table %>% knitr::kable()

# selected attributes

glm_fit_all <- Portdata_main_train %>% 
glm(y_output ~ Duration_group+month+poutcome+Age_group+pdays_group,
data=., family = binomial(link='logit'))
p_hat_logit_all <- predict(glm_fit_all, newdata = Portdata_main_test, type = "response") 
y_hat_logit_all <- ifelse(p_hat_logit_all > 0.25,1, 0) %>% factor

### Cross table of GLM - Selected attributes
CrossTable(Portdata_main_test$y_output, y_hat_logit_all,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

### Confusion matrix of GLM - Selected attributes
conf_glm_all <- confusionMatrix(y_hat_logit_all, 
Portdata_main_test$y_output, mode = "prec_recall", positive = '1')

conf_glm_all

accuracy_glm_all = conf_glm_all$overall[["Accuracy"]]
Sensitivity_glm_all = conf_glm_all$byClass[["Sensitivity"]]
Specificity_glm_all = conf_glm_all$byClass[["Specificity"]]
Precision_glm_all = conf_glm_all$byClass[["Precision"]]
F1_glm_all = conf_glm_all$byClass[["F1"]]


## Binding confusion table for GLM - All attributes
Confusion_table <- bind_rows(Confusion_table,
    data_frame(method = "GLM - Selected attributes", 
    Accuracy =accuracy_glm_all,SensitivityorRecall = 
    Sensitivity_glm_all, Specificity=Specificity_glm_all,
    Precision = Precision_glm_all, F1= F1_glm_all))


Confusion_table %>% knitr::kable()

```

### RPART:

The rpart algorithm works by splitting the dataset recursively, which means that the subsets that arise from a split are further split until a predetermined termination criterion is reached.  At each step, the split is made based on the independent variable that results in the largest possible reduction in heterogeneity of the dependent (predicted) variable.

```{r RPART_data}

# All attributes

model_rpart = rpart(formula = y_output ~ .,
                    data = Portdata_main_train, method = "class")
p_hat_logit <- predict(model_rpart, newdata = Portdata_main_test, type = "class") 

### Cross table of Rpart - All attributes
CrossTable(Portdata_main_test$y_output, p_hat_logit,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

## RPLOT for the model
fancyRpartPlot(model_rpart ,digits=2, type=2,palettes = c("Purples", "Oranges"))

### Confusion matrix of Rpart - All attributes
conf_rpart <- confusionMatrix(p_hat_logit, 
Portdata_main_test$y_output, mode = "prec_recall", positive = '1')

conf_rpart

accuracy_rpart = conf_rpart$overall[["Accuracy"]]
Sensitivity_rpart = conf_rpart$byClass[["Sensitivity"]]
Specificity_rpart = conf_rpart$byClass[["Specificity"]]
Precision_rpart = conf_rpart$byClass[["Precision"]]
F1_rpart = conf_rpart$byClass[["F1"]]

## Binding confusion table for Rpart - All attributes
Confusion_table <- bind_rows(Confusion_table,
       data_frame(method = "Rpart - All attributes", 
       Accuracy =accuracy_rpart,SensitivityorRecall = 
       Sensitivity_rpart, Specificity=Specificity_rpart,
       Precision = Precision_rpart, F1= F1_rpart))

Confusion_table %>% knitr::kable()


# Selected attributes

model_rpart_select = rpart(formula = y_output ~ Duration_group+month+poutcome+Age_group+pdays_group,
                   data = Portdata_main_train, method = "class")

p_hat_logit_select <- predict(model_rpart_select, newdata = Portdata_main_test, type = "class")

### Cross table of Rpart - Selected attributes
CrossTable(Portdata_main_test$y_output, p_hat_logit_select,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

### RPLOT for the model
fancyRpartPlot(model_rpart_select ,digits=2, type=2,palettes = c("Purples", "Oranges"))

### Confusion matrix of Rpart - Selected attributes
conf_rpart_select <- confusionMatrix(p_hat_logit_select, 
Portdata_main_test$y_output,mode = "prec_recall", positive = '1')

conf_rpart_select

accuracy_rpart_select = conf_rpart_select$overall[["Accuracy"]]
Sensitivity_rpart_select = conf_rpart_select$byClass[["Sensitivity"]]
Specificity_rpart_select = conf_rpart_select$byClass[["Specificity"]]
Precision_rpart_select = conf_rpart_select$byClass[["Precision"]]
F1_rpart_select = conf_rpart_select$byClass[["F1"]]

## Binding confusion table for Rpart - Selected attributes
Confusion_table <- bind_rows(Confusion_table,
      data_frame(method = "Rpart - Selected attributes", 
      Accuracy =accuracy_rpart_select,SensitivityorRecall = 
      Sensitivity_rpart_select,Specificity=Specificity_rpart_select
      ,Precision = Precision_rpart_select, F1= F1_rpart_select))

Confusion_table %>% knitr::kable()


```


### Randomforest:

In the random forest approach, a large number of decision trees are created. Every observation is fed into every decision tree. The most common outcome for each observation is used as the final output. A new observation is fed into all the trees and taking a majority vote for each classification model.

```{r RF_data}

# All attributes 

model_rf = randomForest(y_output ~ .,
                    data = Portdata_main_train)

pred_rf <- predict(model_rf, newdata = Portdata_main_test, type = "class") 

### Cross table of RF - All attributes
CrossTable(Portdata_main_test$y_output, pred_rf,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

### Confusion matrix of RF - All attributes
conf_rf <- confusionMatrix(pred_rf, Portdata_main_test$y_output, mode = "prec_recall", positive = '1')

conf_rf

accuracy_rf = conf_rf$overall[["Accuracy"]]
Sensitivity_rf = conf_rf$byClass[["Sensitivity"]]
Specificity_rf = conf_rf$byClass[["Specificity"]]
Precision_rf = conf_rf$byClass[["Precision"]]
F1_rf = conf_rf$byClass[["F1"]]

## Binding confusion table for RF - All attributes
Confusion_table <- bind_rows(Confusion_table,
  data_frame(method = "RF - All attributes", Accuracy =accuracy_rf,
  SensitivityorRecall = Sensitivity_rf, 
  Specificity=Specificity_rf,Precision = Precision_rf, F1= F1_rf))

Confusion_table %>% knitr::kable()

# Selected attributes

model_rf_select = randomForest(y_output ~ Duration_group+month+poutcome+Age_group+pdays_group,
                        data = Portdata_main_train)

pred_rf_select <- predict(model_rf_select, newdata = Portdata_main_test, type = "class") 

### Cross table of RF - Selected attributes
CrossTable(Portdata_main_test$y_output, pred_rf_select,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

### Confusion matrix of RF - Selected attributes
conf_rf_select <- confusionMatrix(pred_rf_select, 
Portdata_main_test$y_output, mode = "prec_recall", positive = '1')

conf_rf_select

accuracy_rf_select = conf_rf_select$overall[["Accuracy"]]
Sensitivity_rf_select = conf_rf_select$byClass[["Sensitivity"]]
Specificity_rf_select = conf_rf_select$byClass[["Specificity"]]
Precision_rf_select = conf_rf_select$byClass[["Precision"]]
F1_rf_select = conf_rf_select$byClass[["F1"]]

## Binding confusion table for RF - Selected attributes
Confusion_table <- bind_rows(Confusion_table,
      data_frame(method = "RF - Selected attributes", 
      Accuracy =accuracy_rf_select,SensitivityorRecall = 
      Sensitivity_rf_select, Specificity=Specificity_rf_select,
      Precision = Precision_rf_select, F1= F1_rf_select))

Confusion_table %>% knitr::kable()
```


### KNN:

K-Nearest Neighbors (KNN) is one of the simplest algorithms used in Machine Learning for regression and classification problem. KNN algorithms use data and classify new data points based on similarity measures (e.g. distance function). Classification is done by a majority vote to its neighbors. The data is assigned to the class which has the nearest neighbors. As you increase the number of nearest neighbors, the value of k, accuracy might increase.

```{r KNN_data}
# ALL Attributes

model_knn <- train(y_output ~ ., data = Portdata_main_train, method = "knn", 
                  maximize = TRUE,
                  trControl = trainControl(method = "cv", number = 10),
                  preProcess=c("center", "scale"))

pred_kNN <- predict(model_knn , Portdata_main_test)

### Cross table of KNN-All attributes
CrossTable(Portdata_main_test$y_output, pred_kNN,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

### Confusion matrix of KNN-All attributes
conf_knn <- confusionMatrix(pred_kNN , Portdata_main_test$y_output, mode = "prec_recall", positive = '1')
conf_knn

accuracy_knn = conf_knn$overall[["Accuracy"]]
Sensitivity_knn = conf_knn$byClass[["Sensitivity"]]
Specificity_knn = conf_knn$byClass[["Specificity"]]
Precision_knn = conf_knn$byClass[["Precision"]]
F1_knn = conf_knn$byClass[["F1"]]

## Binding confusion table for KNN-All attributes
Confusion_table <- bind_rows(Confusion_table,
      data_frame(method = "KNN-All attributes", 
      Accuracy =accuracy_knn,SensitivityorRecall = Sensitivity_knn,
      Specificity=Specificity_knn,Precision = Precision_knn, 
      F1= F1_knn))

Confusion_table %>% knitr::kable()

```

### Confusion Matrix

A confusion matrix is a technique for summarizing the performance of a classification algorithm.

Classification accuracy alone can be misleading if you have an unequal number of observations in each class or if you have more than two classes in your dataset.

Calculating a confusion matrix can give you a better idea of what your classification model is getting right and what types of errors it is making.

As there were many parameters present in the confusion matrix, we were concentrating on the below parameters for our analysis.

Accuracy - Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. One may think that, if we have high accuracy then our model is best. Yes, accuracy is a great measure but only when you have symmetric datasets where values of false positive and false negatives are almost same. Therefore, you have to look at other parameters to evaluate the performance of your model.

Accuracy = TP+TN/TP+FP+FN+TN

Precision - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. 

Precision = TP/TP+FP

Recall (Sensitivity) - Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. 

Recall = TP/TP+FN

Specificity - The proportion of observed negatives that were predicted to be negatives.  In other words, of all the transactions that were legitimate, what percentage did we predict to be so?

Specificity = TN/FP+TN

F1 score - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it’s better to look at both Precision and Recall. 

F1 Score = 2*(Recall * Precision) / (Recall + Precision)

Final confusion matrix table as below:

```{r Confusion_data}
Confusion_table %>% knitr::kable()
```

# Results and Discussion

Based on the above confusion matrix details of all the analysed models, we shortlisted GLM - All attributes and GLM - Selected attributes as the F1 and Recall values are good, and RF - All atrributes and Rf - Selected atrributes as the Accuracy, Precision and Specificity are good.

Hence, we implemented the above 4 models into the Validation set for the final conclusion. 

```{r Final_data}
#GLM:

glm_fit_final <- Portdata_main %>% 
  glm(y_output ~ ., data=., family = binomial(link='logit'))
p_hat_logit_final <- predict(glm_fit_final, newdata = Portdata_validation, type = "response") 
y_hat_logit_final <- ifelse(p_hat_logit_final > 0.25,1, 0) %>% factor

### Cross table of GLM - Final - All
CrossTable(Portdata_validation$y_output, y_hat_logit_final,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

### Confusion matrix of GLM - Final - All
conf_glm_final <- confusionMatrix(y_hat_logit_final, 
Portdata_validation$y_output, mode = "prec_recall", positive = '1')

conf_glm_final

accuracy_glm_final = conf_glm_final$overall[["Accuracy"]]
Sensitivity_glm_final = conf_glm_final$byClass[["Sensitivity"]]
Specificity_glm_final = conf_glm_final$byClass[["Specificity"]]
Precision_glm_final = conf_glm_final$byClass[["Precision"]]
F1_glm_final = conf_glm_final$byClass[["F1"]]

## Creating confusion table final for GLM - Final - All
Confusion_table_final <- data_frame(method = "GLM - Final - All", 
          Accuracy =accuracy_glm_final,
          SensitivityorRecall = Sensitivity_glm_final, 
          Specificity=Specificity_glm_final,
          Precision = Precision_glm_final, F1= F1_glm_final  )

Confusion_table_final <- as.data.frame(Confusion_table_final)

Confusion_table_final %>% knitr::kable()

# Selected attributes

glm_fit_select_final <- Portdata_main %>% 
glm(y_output ~ Duration_group+month+poutcome+Age_group+pdays_group,
data=., family = binomial(link='logit'))
p_hat_logit_select_final <- predict(glm_fit_select_final, newdata =
      Portdata_validation, type = "response") 
y_hat_logit_select_final <- ifelse(p_hat_logit_select_final > 0.25,1, 0) %>% factor

### Cross table of GLM - Final - selected
CrossTable(Portdata_validation$y_output, y_hat_logit_select_final,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

### Confusion matrix of GLM - Final - selected
conf_glm_select_final <- confusionMatrix(y_hat_logit_select_final, 
Portdata_validation$y_output, mode = "prec_recall", positive = '1')

conf_glm_select_final

accuracy_glm_select_final = conf_glm_select_final$overall[["Accuracy"]]
Sensitivity_glm_select_final = conf_glm_select_final$byClass[["Sensitivity"]]
Specificity_glm_select_final = conf_glm_select_final$byClass[["Specificity"]]
Precision_glm_select_final = conf_glm_select_final$byClass[["Precision"]]
F1_glm_select_final = conf_glm_select_final$byClass[["F1"]]

## Binding confusion table final for GLM - Final - selected
Confusion_table_final <- bind_rows(Confusion_table_final,
      data_frame(method = "GLM - Final - selected", 
      Accuracy =accuracy_glm_select_final,SensitivityorRecall = 
      Sensitivity_glm_select_final, 
      Specificity=Specificity_glm_select_final,Precision =      
      Precision_glm_select_final, F1= F1_glm_select_final))


Confusion_table_final %>% knitr::kable()


##Randomforest

# All attributes 

model_rf_final = randomForest(y_output ~ .,
                        data = Portdata_main)

pred_rf_final <- predict(model_rf_final, newdata = Portdata_validation, type = "class") 

### Cross table of RF - Final - All
CrossTable(Portdata_validation$y_output, pred_rf_final,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

### Confusion matrix of RF - Final - All
conf_rf_final <- confusionMatrix(pred_rf_final, 
Portdata_validation$y_output, mode = "prec_recall", positive = '1')

conf_rf_final

accuracy_rf_final = conf_rf_final$overall[["Accuracy"]]
Sensitivity_rf_final = conf_rf_final$byClass[["Sensitivity"]]
Specificity_rf_final = conf_rf_final$byClass[["Specificity"]]
Precision_rf_final = conf_rf_final$byClass[["Precision"]]
F1_rf_final = conf_rf_final$byClass[["F1"]]

## Binding confusion table final for RF - Final - All
Confusion_table_final <- bind_rows(Confusion_table_final,
    data_frame(method = "RF - Final - All", 
    Accuracy =accuracy_rf_final,SensitivityorRecall = 
    Sensitivity_rf_final,Specificity=Specificity_rf_final,
    Precision = Precision_rf_final, F1= F1_rf_final))

Confusion_table_final %>% knitr::kable()


# Selected attributes

model_rf_select_final = randomForest(y_output ~ Duration_group+month+poutcome+Age_group+pdays_group,
                               data = Portdata_main)

pred_rf_select_final <- predict(model_rf_select_final, newdata = Portdata_validation, type = "class") 

### Cross table of RF - Final - Selected
CrossTable(Portdata_validation$y_output, pred_rf_select_final,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

### Confusion matrix of RF - Final - Selected
conf_rf_select_final <- confusionMatrix(pred_rf_select_final, 
Portdata_validation$y_output, mode = "prec_recall", positive = '1')

conf_rf_select_final

accuracy_rf_select_final = conf_rf_select_final$overall[["Accuracy"]]
Sensitivity_rf_select_final = conf_rf_select_final$byClass[["Sensitivity"]]
Specificity_rf_select_final = conf_rf_select_final$byClass[["Specificity"]]
Precision_rf_select_final = conf_rf_select_final$byClass[["Precision"]]
F1_rf_select_final = conf_rf_select_final$byClass[["F1"]]

## Binding confusion table final for RF - Final - Selected
Confusion_table_final <- bind_rows(Confusion_table_final,
      data_frame(method = "RF - Final - Selected", 
      Accuracy =accuracy_rf_select_final,
      SensitivityorRecall = Sensitivity_rf_select_final, 
      Specificity=Specificity_rf_select_final,Precision = 
      Precision_rf_select_final, F1= F1_rf_select_final))

Confusion_table_final %>% knitr::kable()

```

The best accuracy(0.9075) came for the RandomForest model with all attributes. The second best accuracy(0.9024) came for the RandomForest model with selected attributes.

The best sensitivity or Recall(0.6275) came for the GLM model with all attributes. The second best sensitivity(0.6143) came for the GLM model with selected attributes.

The best specificity(0.9719) came for the RandomForest model with selected attributes. The second best specificity(0.9644) came for the RandomForest model with all attributes.

The best Precision(0.64102) came for the RandomForest model with selected attributes. The second best Precision (0.6405) came for the RandomForest model with all attributes.

The best F1 (0.5763) came for the GLM model with all attributes. The second best F1(0.5536) came for the GLM model with selected attributes.

# Conclusion

We have built a machine learning algorithm with different models to predict whether a client will subscribe the term deposit or not. We ran through different algorithms like GLM, RPART, RandomForest and Knn with all attributes and selected attributes. Finally, we have concentrated on the GLM and RandonForest algorithms based on the initial testing results. GLM all attributes and selected attributes had good results on Sensitivity or Recall and F1 values whereas RandomForest all attributes and selected attributes had good values of Accuracy, Specificity and Precision. Based on the collective observations, we can conclude that RandonForest model is a better fit for this Portugues marketing dataset analysis. Instead of selecting 5 attributes, we can run all the algorithms with different sets of attributes in a series. But this will become a lengthy analysis and difficult to conclude in a better way. It is also time-consuming and does not give a desirable outcome.

\pagebreak

# Appendix - Environment

```{r}
print("Operating System:")
version
```